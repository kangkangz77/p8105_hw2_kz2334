---
title: "Homework 2"
author: "Kangkang Zhang"
date: "10/2/2018"
output: github_document
---

##Problem 1

Load package tidyverse.
```{r 1.1}
library(tidyverse)
```

Read NYC Transit data and do data cleaning as question required.
```{r 1.2}
transit_data = read_csv("./data/NYC_transit.csv") %>% 
  janitor::clean_names() %>%  
  select(line, station_name, station_latitude, station_longitude,
         starts_with("route"), entry, vending, entrance_type, ada) %>% 
   mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

This dataset is about New York transportation. It contains variables including line, station name / latitude / longitute, routes served, entry, vending, entrance_type and ADA compliance.

Here is the data cleaning step:

1.   clean up variables'names.
1.   retain variables the question mentioned.
1.   convert the entry variable from character to logical.

The dimension of the dataset is (`r dim(transit_data)`).

The data are not tidy. Because some variables, such like the factor that whether a station served for A line, have values appear in different columns among route1 - route11. 

----------------------------

Use distinct function to find out number of distinct stations.
```{r 1.3}
distinct(transit_data, line, station_name)
```
There are 465 distinct stations.

----------------------------

Use filter and distinct to find out number of stations which are ADA compliant.
```{r 1.4}
transit_data %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name, ada)
```
82 stations are ADA compliant.

----------------------------

Use filter to find out proportion of station entrances / exits without vending allow entrance.
```{r 1.5}
entry_data = filter(transit_data, vending == "NO" & entry == TRUE) 
dim(entry_data)[1] / dim(transit_data)[1]
```
There are 3.69% station entrances / exits without vending allow entrance.

----------------------------

Reformat the dataset with distinct route name and route number.
```{r 1.6}
route_data = gather(transit_data, key = route_number, value = route_name, route1:route11) %>% 
  filter(is.na(route_name) == FALSE)
```

----------------------------

Find out the number of distinct stations serve the A train and the number of ADA compliant of them.
```{r 1.7}
route_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, route_name)
```
60 stations serve the A train.

----------------------------

```{r 1.8}
route_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, route_name, ada) %>% 
  filter(ada == TRUE)
```
17 stations which serve the A train are ADA compliant.

----------------------------

##Problem 2

Read and clean the Mr. Trash Wheel sheet.
```{r 2.1}
library(readxl)
trash_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                        range = "Mr. Trash Wheel!A2:N388") %>% 
  janitor::clean_names() %>% 
  filter(is.na(dumpster) == FALSE) %>% 
  mutate(weight = weight_tons, volume = volume_cubic_yards, 
          sports_balls = as.integer(round(sports_balls, 0))) %>% 
  select(- weight_tons, - volume_cubic_yards)
trash_data
```

----------------------------------------

Read precipitation data for 2016 and 2017. Add year variable.
```{r 2.2}
prcp_2016_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                            range = "2016 Precipitation!A2:B14") %>% 
  mutate(year = 2016)
prcp_2017_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                            range = "2017 Precipitation!A2:B14") %>% 
  mutate(year = 2017)
```

----------------------------------------

Combine datasets and convert month to a character variable.
```{r 2.3}
prcp_data = rbind(prcp_2016_data, prcp_2017_data) %>% 
  janitor::clean_names() %>% 
  mutate(month = month.name[month])
prcp_data
```

**Mr. Trash Wheel dataset**:

*   The number of observations is `r dim(trash_data)[1]`. 
*   The mean weight of  dumpsters is `r round(mean(trash_data$weight), 2)` tons. 
*   Maximum weight of dumpsters is `r round(max(trash_data$weight), 2)` tons.
*   Minimum weight of dumpsters is `r round(min(trash_data$weight), 2)` tons.
*   The mean homes powered of dumpsters is `r round(mean(trash_data$homes_powered))`.

**2016 and 2017 precipitation dataset**:

*   The number of observations is `r dim(prcp_data)[1]`. 
*   The average monthly precipitation in 2016 and 2017 is `r round(mean(prcp_data$total), 2)` in. 
*   Maximum monthly precipitation in 2016 and 2017 is `r round(max(prcp_data$total), 2)` tons.
*   Minimum monthly precipitation in 2016 and 2017 is `r round(min(prcp_data$total), 2)` tons.

The total precipitation in 2017 was `r round(mean(prcp_2017_data$Total), 2)`.
```{r 2.4, echo = FALSE}
trash_data_2016 = filter(trash_data, year == 2016) 
```

The median number of sports balls in a dumpster in 2016 was `r  median(trash_data_2016$sports_balls)`.

##Problem 3

Load the BRFSS data from the p8105.datasets package.
```{r 3.1}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(brfss_smart2010)
```

--------------------------------

Clean up variable names and exclude specific variables.
```{r 3.2}
brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select( - class, - topic, - question, - sample_size, 
          - confidence_limit_low:- geo_location)
```

Structure data for values of response. Create a new variable showing the proportion of responses that were “Excellent” or “Very Good”.
```{r 3.3}
brfss_data = brfss_data %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>%
  mutate(excl_or_vrgd = excellent + very_good)
```

---------------------------------------

Find out there are how many distinct locations.
```{r 3.4}
brfss_data %>% 
  count(locationdesc)   
```

There are 404 unique locations are included in the dataset. 

-------------

Find out the most observed state.
```{r 3.5}
brfss_data %>% 
  count(locationabbr) %>% 
  arrange(desc(n))
```

Every state is represented. NJ state is observed the most.